{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5608b50b",
   "metadata": {},
   "source": [
    "# Apply the trained classifier to the full image\n",
    "\n",
    "In this notebook, we will apply the trained `RandomForestClassifier` to the full image, to predict the waterbodies and non-waterbodies across the entire AOI. We will use Dask to distribute the prediction process across multiple chunks of the image, which allows us to handle large images efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rioxarray\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "\n",
    "import joblib  # For save and load of the model\n",
    "\n",
    "from dask.distributed import Client, LocalCluster, Lock\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc91eb",
   "metadata": {},
   "source": [
    "## Overview AoI\n",
    "\n",
    "First, let's take another look at the area of interest (AoI) by visualizing the COG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize the full RGB with overviews\n",
    "path_rgb_full = Path(\"data/sentinel2_rgb_res_20_size_8000_cog.tif\")\n",
    "rgb_full = rioxarray.open_rasterio(\n",
    "    path_rgb_full, overview_level=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "rgb_full.plot.imshow(ax=ax, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db23fa",
   "metadata": {},
   "source": [
    "## Load data and trained model\n",
    "\n",
    "In the following steps, we will load the full RGB image chunk-wise. Depends on the computation infrastructure, we can adjust the chunk size accordingly. With the `chunks` input argument in `rioxarray.open_rasterio`, we can \"lazily\" load the large image, i.e. create a task graph for loading the data in chunks, which will be executed later when we actually need the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure chunksize for the later processing\n",
    "CHUNKSIZE = 2000\n",
    "\n",
    "# Lazy loading of the RGB data, automatically chunked\n",
    "rgb = rioxarray.open_rasterio(path_rgb_full, chunks={'band': -1, 'y': CHUNKSIZE, 'x': CHUNKSIZE})\n",
    "rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47445ed",
   "metadata": {},
   "source": [
    "We load load the trained classifier from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6176c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('binary_classifier_waterbody.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c901aa8",
   "metadata": {},
   "source": [
    "## Distributed prediction on large data\n",
    "\n",
    "We will initialize a Dask client, which connects to a Dask cluster for distributed computing. On an HPC infrastructure with SLURM, one can use the `dask-jobqueue` to start a Dask SLURM cluster, and connect to it using the cluster. When running locally, we can use the `LocalCluster` to start a local Dask cluster.\n",
    "\n",
    "One can inspect the process through the dashboard link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DASK CLUSTER HERE\n",
    "\n",
    "# OR USE LOCAL DASK CLUSTER\n",
    "local_cluster = LocalCluster(n_workers=3)\n",
    "client = Client(local_cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a03e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on each band - keep it lazy\n",
    "def predict_chunk(chunk, classifier):\n",
    "    \"\"\"Predict on a chunk of data\"\"\"\n",
    "    # chunk is now an xarray DataArray\n",
    "    original_shape = chunk.shape\n",
    "    reshaped = chunk.data.reshape((chunk.shape[0], -1)).T\n",
    "    \n",
    "    # Predict probabilities\n",
    "    probs = classifier.predict_proba(reshaped)\n",
    "\n",
    "    # Reshape back to spatial dimensions with probability classes\n",
    "    result = probs.T.reshape((2, original_shape[1], original_shape[2]))\n",
    "    \n",
    "    # Return as xarray DataArray with proper coordinates\n",
    "    return xr.DataArray(\n",
    "        result,\n",
    "        dims=['band', 'y', 'x'],\n",
    "        coords={\n",
    "            'band': [0, 1],  # non-waterbody, waterbody\n",
    "            'y': chunk['y'],\n",
    "            'x': chunk['x']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89785b7",
   "metadata": {},
   "source": [
    "Now we will apply the trained classifier to the full image in chunks. Many Python libraries, such as `numpy` functions, can work with Dask arrays directly, in those case we can directly use the Dask array as input. However since the `predict` function of `sklearn` classifiers does not support Dask arrays, we will use xarray's `map_blocks` function to apply the classifier to each chunk of the image. This function is suitable in this case, since the prediction can be applied independently to each chunk of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply prediction function using xarray.map_blocks\n",
    "predictions = xr.map_blocks(\n",
    "    predict_chunk,\n",
    "    rgb,\n",
    "    args=[classifier],\n",
    "    template=xr.DataArray(\n",
    "        da.zeros((2, rgb.sizes['y'], rgb.sizes['x']), chunks=(-1, CHUNKSIZE, CHUNKSIZE)),\n",
    "        dims=['band', 'y', 'x'],\n",
    "        coords={\n",
    "            'band': [0, 1],\n",
    "            'y': rgb['y'],\n",
    "            'x': rgb['x']\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec524c",
   "metadata": {},
   "source": [
    "One can also visualize the task graph of the prediction process using Dask's `visualize` function. Note that this requires the `graphviz` package to be installed in the environment, which has been added to the `environment.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8933dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.visualize(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b0660",
   "metadata": {},
   "source": [
    "## Save predictions\n",
    "\n",
    "Now the `predictions` variable has not been computed yet, it is still a Dask array with a task graph. There are multiple ways to compute the predictions. For example, one can use the `compute` method to evaluate the results, and collect the results in memory, if the scheduler memory capacity allows it. \n",
    "\n",
    "One can also save the predictions directly to a file, with the possibility to save each chunk directly without collecting the results in the memory of the scheduler.\n",
    "\n",
    "In this example, we will save the predictions to a COG file, which is a nice option for visualizing large raster data. Unfortunately, `rioxarray` does not support parallel saving of COG files, so here we will collect the results per band, and save each band as a separate COG file.\n",
    "\n",
    "In the later cells (commented out by default), we also provided examples of:\n",
    "- parallel saving to a normal GeoTIFF file\n",
    "- parallel saving to Zarr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each band of the predictions to separate COG\n",
    "# takes ~7 mins\n",
    "predictions.isel(band=0).rio.to_raster(\"./predictions_non_waterbody.tif\", driver=\"COG\")\n",
    "predictions.isel(band=1).rio.to_raster(\"./predictions_waterbody.tif\", driver=\"COG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f903ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel save to a normal GeoTIFF, by specifying lock\n",
    "# However this does not support COG\n",
    "\n",
    "# tiff_output_non_water = \"./predictions_waterbody_full_none_water.tif\"\n",
    "# tiff_output_water = \"./predictions_waterbody_full_water.tif\"\n",
    "\n",
    "# predictions.isel(band=0).rio.to_raster(\n",
    "#     tiff_output_non_water,\n",
    "#     tiled=True,\n",
    "#     lock=Lock(\"rio\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1269d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When data is larger than 4GB, zarr is a better option than geo tiff\n",
    "\n",
    "# predictions.to_zarr(\n",
    "#     \"predictions_waterbody_full.zarr\",\n",
    "#     mode=\"w\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200c40b",
   "metadata": {},
   "source": [
    "## Plot predictions\n",
    "\n",
    "Now we can visualize the predictions. First let's load the entire saved predictions with overview level, and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5acccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved predictions with overview level\n",
    "predictions_water = rioxarray.open_rasterio(\"./predictions_waterbody.tif\", overview_level=1)\n",
    "predictions_non_water = rioxarray.open_rasterio(\"./predictions_non_waterbody.tif\", overview_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the full predictions\n",
    "img_extent = (predictions_water.x.min(), predictions_water.x.max(), predictions_water.y.min(), predictions_water.y.max())\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "rgb_full.plot.imshow(ax=axes[0], robust=True)\n",
    "axes[0].imshow(predictions_non_water.data.squeeze(), cmap='Reds', alpha=0.8, extent=img_extent)\n",
    "axes[0].set_title('Non-waterbody Probability')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(axes[0].images[1], ax=axes[0], shrink=0.7)\n",
    "rgb_full.plot.imshow(ax=axes[1], alpha=0.6, robust=True)\n",
    "axes[1].imshow(predictions_water.data.squeeze(), cmap='Blues', alpha=0.8, extent=img_extent)\n",
    "axes[1].set_title('Waterbody Probability')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(axes[1].images[1], ax=axes[1], shrink=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5862bc8",
   "metadata": {},
   "source": [
    "We can also load the results lazily and zoom into specific areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved predictions with overview level\n",
    "predictions_water = rioxarray.open_rasterio(\"./predictions_waterbody.tif\", chunks={'band': -1, 'y': CHUNKSIZE, 'x': CHUNKSIZE})\n",
    "predictions_non_water = rioxarray.open_rasterio(\"./predictions_non_waterbody.tif\", chunks={'band': -1, 'y': CHUNKSIZE, 'x': CHUNKSIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d37ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a cutout for visualization\n",
    "# South west Friesland\n",
    "y_idx_range = slice(100, 2100)\n",
    "x_idx_range = slice(200, 2200)\n",
    "predictions_water_cutout = predictions_water.isel(\n",
    "    y=y_idx_range,\n",
    "    x=x_idx_range\n",
    ")\n",
    "predictions_non_water_cutout = predictions_non_water.isel(\n",
    "    y=y_idx_range,\n",
    "    x=x_idx_range\n",
    ")\n",
    "rgb_cutout = rgb.isel(\n",
    "    y=y_idx_range,\n",
    "    x=x_idx_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cutout predictions\n",
    "img_extent = (predictions_water_cutout.x.min(), predictions_water_cutout.x.max(), predictions_water_cutout.y.min(), predictions_water_cutout.y.max())\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "rgb_cutout.plot.imshow(ax=axes[0], robust=True)\n",
    "axes[0].imshow(predictions_non_water_cutout.data.squeeze(), cmap='Reds', alpha=0.8, extent=img_extent)\n",
    "axes[0].set_title('Non-waterbody Probability')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(axes[0].images[1], ax=axes[0], shrink=0.7)\n",
    "rgb_cutout.plot.imshow(ax=axes[1], alpha=0.6, robust=True)\n",
    "axes[1].imshow(predictions_water_cutout.data.squeeze(), cmap='Blues', alpha=0.8, extent=img_extent)\n",
    "axes[1].set_title('Waterbody Probability')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(axes[1].images[1], ax=axes[1], shrink=0.7)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo-summer-school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
